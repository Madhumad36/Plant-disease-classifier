# -*- coding: utf-8 -*-
"""newplantdisese.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RTvC3R_mnFLBjBxuYIuJPoeIdYzbNT8G
"""

import os
import shutil
import numpy as np
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# --- 1. Configuration (Using Your Drive Paths) ---

# Input Path: Contains the 4 class folders (e.g., 'Pepper_bell___healthy')
DATA_ROOT = '/content/drive/MyDrive/PlantVillage'

# Output Path: Where the new 'train', 'valid', and 'test' folders will be created
OUTPUT_ROOT = '/content/drive/MyDrive/output.dataplant'

# Define the split ratios (must sum to 1.0)
TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1

# --- 2. Collect Images and Labels ---
print("Collecting image paths and labels for 4 classes...")
all_files = []
all_labels = []

# List all items in the DATA_ROOT folder
for class_name in os.listdir(DATA_ROOT):
    class_path = os.path.join(DATA_ROOT, class_name)

    # We only process directories that contain the images
    if os.path.isdir(class_path):
        for image_name in os.listdir(class_path):
            if image_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                all_files.append(os.path.join(class_path, image_name))
                all_labels.append(class_name) 

print(f"Total images found: {len(all_files)}")
print(f"Classes being used: {sorted(list(set(all_labels)))}")


# --- 3. Split the Data Indices (Train/Val/Test) ---

# 1. Split into (Train + Validation) and Test sets (90% and 10%)
X_temp, X_test, y_temp, y_test = train_test_split(
    all_files, all_labels,
    test_size=TEST_RATIO,
    random_state=42,
    shuffle=True,
    stratify=all_labels
)

# 2. Split the temporary set into Train and Validation sets (e.g., 80% and 10%)
VAL_SIZE_RELATIVE = VAL_RATIO / (TRAIN_RATIO + VAL_RATIO)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp,
    test_size=VAL_SIZE_RELATIVE,
    random_state=42,
    shuffle=True,
    stratify=y_temp
)

# Print the final counts
print(f"\nTraining images:   {len(X_train)}")
print(f"Validation images: {len(X_val)}")
print(f"Testing images:    {len(X_test)}")


# --- 4. Create Directories and Copy Files ---
def create_and_copy(file_list, label_list, split_name):
    """Creates the target directory structure and copies the files."""
    # Use tqdm to show a progress bar
    for file_path, label in tqdm(zip(file_list, label_list), desc=f"Copying {split_name} files", total=len(file_list)):

        # Target path format: OUTPUT_ROOT/train/Pepper_bell___healthy/filename.jpg
        target_dir = os.path.join(OUTPUT_ROOT, split_name, label)
        os.makedirs(target_dir, exist_ok=True)

        file_name = os.path.basename(file_path)

        # Copy the file
        shutil.copy(file_path, os.path.join(target_dir, file_name))

# Clean up previous split in the output folder if it exists
if os.path.exists(OUTPUT_ROOT):
    # This step is commented out to prevent accidental deletion,

create_and_copy(X_train, y_train, 'train')
create_and_copy(X_val, y_val, 'valid')
create_and_copy(X_test, y_test, 'test')

print(f"\nâœ… Data split and organized successfully in: {OUTPUT_ROOT}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import os

# --- Configuration for 4-Class Project ---

BASE_DIR = '/content/drive/MyDrive/output.dataplant'
train_dir = os.path.join(BASE_DIR, 'train')
valid_dir = os.path.join(BASE_DIR, 'valid')
test_dir = os.path.join(BASE_DIR, 'test') # For final evaluation later

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10
NUM_CLASSES = 4 

# --- Data Augmentation and Generator Setup ---

# 1. Training Generator: Apply transformations and normalize
train_datagen = ImageDataGenerator(
    rescale=1./255, # Normalize
    rotation_range=40,
    horizontal_flip=True,
    fill_mode='nearest'
)

# 2. Validation/Test Generator: Only normalize
valid_test_datagen = ImageDataGenerator(rescale=1./255)

# Load data into generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical' # Important for multi-class problems
)

validation_generator = valid_test_datagen.flow_from_directory(
    valid_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

print(f"Detected Classes (Labels): {train_generator.class_indices}")

# --- Build the Transfer Learning Model (MobileNetV2) ---

# 1. Load the pre-trained MobileNetV2 base model
base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,        # Exclude the original classification head
    weights='imagenet'        # Use ImageNet weights
)

# 2. Freeze the base model
base_model.trainable = False

# 3. Add custom classification layers (the 'head')
model = tf.keras.Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5), # Regularization to prevent overfitting
    Dense(512, activation='relu'),
    # Final layer: 4 neurons (for 4 classes) with Softmax activation
    Dense(NUM_CLASSES, activation='softmax')
])

# 4. Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    # Categorical Crossentropy for multi-class classification
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# --- Define Callbacks ---
model_save_path = '/content/drive/MyDrive/output.dataplant/best_4_class_model.keras'

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    model_save_path,
    monitor='val_accuracy',
    save_best_only=True
)

# --- Train the Model ---
print("\n--- Starting Training (Phase 1: Frozen Base) ---")

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

print(f"\nModel saved to: {model_save_path}")

# Function to visualize training history
def plot_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # Plot Accuracy
    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title('Training and Validation Accuracy')
    ax1.legend()

    # Plot Loss
    ax2.plot(history.history['loss'], label='Training Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title('Training and Validation Loss')
    ax2.legend()
    plt.show()

plot_history(history)

from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd

# Load the best saved model
best_model = load_model(model_save_path)

# Create a generator for the test set (no shuffling, single pass)
test_generator = valid_test_datagen.flow_from_directory(
    test_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False # Crucial: Keep order for evaluation
)

# Evaluate the model
loss, accuracy = best_model.evaluate(test_generator)
print(f"\n--- Final Test Set Evaluation ---")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy*100:.2f}%")

# Generate Classification Report (more detailed metrics)
Y_pred = best_model.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes
class_names = list(test_generator.class_indices.keys())

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred, target_names=class_names))

print("\n--- Confusion Matrix ---")
cm = confusion_matrix(y_true, y_pred)
cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)
print(cm_df)

# Example usage with a sample image URL (replace with your image path or URL)
# This is an example URL, replace it with a URL to an image of a pepper or tomato leaf
sample_image_url = 'https://www.plantdiseases.org/bacterial-spot-pepper-0'

try:
    # Download the image from the URL (if it's a URL)
    # If you are using a local file path, you don't need this part
    import requests
    from PIL import Image
    from io import BytesIO

    response = requests.get('https://www.plantdiseases.org/sites/default/files/plant_disease/images/0706.jpg')
    img = Image.open(BytesIO(response.content))
    img.save("sample_image.jpg") # Save the downloaded image temporarily
    sample_image_path = "sample_image.jpg"

except Exception as e:
    print(f"Error downloading image: {e}")
    sample_image_path = None # Set to None if download fails

if sample_image_path:
    result_class, result_conf = predict_new_image(sample_image_path)
    print(f"Prediction: {result_class} with {result_conf:.2f}% confidence")

    # Clean up the temporary image file
    if os.path.exists(sample_image_path):
        os.remove(sample_image_path)

else:
    print("Could not process the sample image.")

sample_image_url = 'https://www.google.com/imgres?imgurl=https%3A%2F%2Fcontent.peat-cloud.com%2Fw400%2Fbacterial-spot-of-pepper-pepper-1560240277.jpg&tbnid=AJNL6-6VdrbSWM&vet=10CAgQxiAoA2oXChMI2K3RptOrkAMVAAAAAB0AAAAAEAo..i&imgrefurl=https%3A%2F%2Fplantix.net%2Fen%2Flibrary%2Fplant-diseases%2F300003%2Fbacterial-spot-of-pepper%2F&docid=91YHVmEPI2SzaM&w=400&h=300&itg=1&q=bell%20pepper%20bacterial%20leaf%20spot&ved=0CAgQxiAoA2oXChMI2K3RptOrkAMVAAAAAB0AAAAAEAo0'

try:
    # Download the image from the URL (if it's a URL)
    # If you are using a local file path, you don't need this part
    import requests
    from PIL import Image
    from io import BytesIO

    response = requests.get('https://content.peat-cloud.com/w400/bacterial-spot-of-pepper-pepper-1560240277.jpg')
    img = Image.open(BytesIO(response.content))
    img.save("sample_image.jpg") # Save the downloaded image temporarily
    sample_image_path = "sample_image.jpg"

except Exception as e:
    print(f"Error downloading image: {e}")
    sample_image_path = None # Set to None if download fails

if sample_image_path:
    result_class, result_conf = predict_new_image(sample_image_path)
    print(f"Prediction: {result_class} with {result_conf:.2f}% confidence")

    # Clean up the temporary image file
    if os.path.exists(sample_image_path):
        os.remove(sample_image_path)

else:
    print("Could not process the sample image.")

sample_image_url = 'https://www.google.com/imgres?q=bell%20pepper%20bacterial%20leaf%20spot&imgurl=https%3A%2F%2Fplant-pest-advisory.rutgers.edu%2Fwp-content%2Fuploads%2F2022%2F07%2Fkorean-anthrac-fruit-infection-scaled.jpg&imgrefurl=https%3A%2F%2Fplant-pest-advisory.rutgers.edu%2Fdiagnosing-important-diseases-in-pepper-reference-guide%2F&docid=G9IiqqqEUanDVM&tbnid=dDq3EsbzBiAC-M&vet=12ahUKEwiL8abN06uQAxUnxTgGHVItEKg4ChAzegQISxAA..i&w=1440&h=2560&hcb=2&ved=2ahUKEwiL8abN06uQAxUnxTgGHVItEKg4ChAzegQISxAA'

try:
    # Download the image from the URL (if it's a URL)
    # If you are using a local file path, you don't need this part
    import requests
    from PIL import Image
    from io import BytesIO

    response = requests.get('https://plant-pest-advisory.rutgers.edu/wp-content/uploads/2022/07/korean-anthrac-fruit-infection-scaled.jpg')
    img = Image.open(BytesIO(response.content))
    img.save("sample_image.jpg") # Save the downloaded image temporarily
    sample_image_path = "sample_image.jpg"

except Exception as e:
    print(f"Error downloading image: {e}")
    sample_image_path = None # Set to None if download fails

if sample_image_path:
    result_class, result_conf = predict_new_image(sample_image_path)
    print(f"Prediction: {result_class} with {result_conf:.2f}% confidence")

    # Clean up the temporary image file
    if os.path.exists(sample_image_path):
        os.remove(sample_image_path)

else:
    print("Could not process the sample image.")

sample_image_url = 'https://www.google.com/imgres?q=tomato%20bacterial%20leaf%20spot&imgurl=https%3A%2F%2Fcontent.peat-cloud.com%2Fw400%2Fbacterial-spot-and-speck-of-tomato-tomato-1584010249.jpg&imgrefurl=https%3A%2F%2Fplantix.net%2Fen%2Flibrary%2Fplant-diseases%2F300050%2Fbacterial-spot-and-speck-of-tomato%2F&docid=-liwuqRxbEWD1M&tbnid=WtQsvWSNhzmU3M&vet=12ahUKEwjLtdCa1KuQAxWhyzgGHVyyL8QQM3oECB4QAA..i&w=400&h=533&hcb=2&ved=2ahUKEwjLtdCa1KuQAxWhyzgGHVyyL8QQM3oECB4QAA#imgrc=WtQsvWSNhzmU3M&imgdii=Zci0NcB3loGGCM'

try:
    # Download the image from the URL (if it's a URL)
    # If you are using a local file path, you don't need this part
    import requests
    from PIL import Image
    from io import BytesIO

    response = requests.get('https://assets.revistacultivar.com.br/622ef-Controle-da-mancha-bacteriana-em-tomate.jpg')
    img = Image.open(BytesIO(response.content))
    img.save("sample_image.jpg") # Save the downloaded image temporarily
    sample_image_path = "sample_image.jpg"

except Exception as e:
    print(f"Error downloading image: {e}")
    sample_image_path = None # Set to None if download fails

if sample_image_path:
    result_class, result_conf = predict_new_image(sample_image_path)
    print(f"Prediction: {result_class} with {result_conf:.2f}% confidence")

    # Clean up the temporary image file
    if os.path.exists(sample_image_path):
        os.remove(sample_image_path)

else:
    print("Could not process the sample image.")

sample_image_url = 'https://www.google.com/imgres?q=tomato%20bacterial%20leaf%20spot&imgurl=https%3A%2F%2Fwww.ontario.ca%2Ffiles%2F2022-01%2Fomafra-bacterial-diseases-of-tomato-figure-9-en-4032x2688-2021-12-09-v1.jpg&imgrefurl=https%3A%2F%2Fwww.ontario.ca%2Fpage%2Fbacterial-diseases-tomato-bacterial-spot-bacterial-speck-and-bacterial-canker&docid=B6D5Hf9Dl52XYM&tbnid=xc1pteIYvxnweM&vet=12ahUKEwjLtdCa1KuQAxWhyzgGHVyyL8QQM3oECBUQAA..i&w=4032&h=2688&hcb=2&ved=2ahUKEwjLtdCa1KuQAxWhyzgGHVyyL8QQM3oECBUQAA'

try:
    # Download the image from the URL (if it's a URL)
    # If you are using a local file path, you don't need this part
    import requests
    from PIL import Image
    from io import BytesIO

    response = requests.get('https://apps.lucidcentral.org/pppw_v12/images/entities/tomato_bacterial_spot_081/fs81_bacterial_spot_page_1_image_0001.jpg')
    img = Image.open(BytesIO(response.content))
    img.save("sample_image.jpg") # Save the downloaded image temporarily
    sample_image_path = "sample_image.jpg"

except Exception as e:
    print(f"Error downloading image: {e}")
    sample_image_path = None # Set to None if download fails

if sample_image_path:
    result_class, result_conf = predict_new_image(sample_image_path)
    print(f"Prediction: {result_class} with {result_conf:.2f}% confidence")

    # Clean up the temporary image file
    if os.path.exists(sample_image_path):
        os.remove(sample_image_path)

else:
    print("Could not process the sample image.")
